{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                      Ok lar... Joking wif u oni...      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Text\n",
    "Y = df.Label\n",
    "# Y = LabelEncoder().fit_transform(Y)\n",
    "Y = Y.values.reshape(-1,1)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow only 1000 most frequent words in the whole corpus\n",
    "max_words = 1000\n",
    "to_token = Tokenizer(num_words=max_words)\n",
    "to_token.fit_on_texts(X_train)\n",
    "\n",
    "# Pad every message to 150 words max!\n",
    "max_len = 150\n",
    "sequences = to_token.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    '''Define RNN model in keras layer-by-layer'''\n",
    "    # model = Sequential()\n",
    "    # model.add()\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 948 samples\n",
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 6s 2ms/step - loss: 0.3301 - acc: 0.8820 - val_loss: 0.1499 - val_acc: 0.9641\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 6s 1ms/step - loss: 0.0882 - acc: 0.9802 - val_loss: 0.0514 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 6s 2ms/step - loss: 0.0415 - acc: 0.9886 - val_loss: 0.0726 - val_acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a96658ac18>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 1s 603us/step\n",
      "Test set\n",
      "  Loss: 0.101\n",
      "  Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "output = model.predict(test_sequences_matrix)\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     v2  prediction\n",
      "4590  Well done ENGLAND! Get the official poly ringt...    0.999231\n",
      "2766  Married local women looking for discreet actio...    0.999025\n",
      "3215  URGENT! We are trying to contact U. Todays dra...    0.998961\n",
      "1016  FREE for 1st week! No1 Nokia tone 4 ur mob eve...    0.998769\n",
      "311   Think ur smart ? Win å£200 this week in our we...    0.998726\n",
      "2307  WIN a year supply of CDs 4 a store of ur choic...    0.998670\n",
      "12    URGENT! You have won a 1 week FREE membership ...    0.998549\n",
      "4089  We tried to call you re your reply to our sms ...    0.998490\n",
      "4645  We tried to contact you re your reply to our o...    0.998471\n",
      "4125  SPJanuary Male Sale! Hot Gay chat now cheaper,...    0.998422\n",
      "2879  Last Chance! Claim ur å£150 worth of discount ...    0.998284\n",
      "934   Dear Matthew please call 09063440451 from a la...    0.998253\n",
      "3893  Dear Dave this is your final notice to collect...    0.998117\n",
      "5342  u r subscribed 2 TEXTCOMP 250 wkly comp. 1st w...    0.998006\n",
      "3421  Freemsg: 1-month unlimited free calls! Activat...    0.997983\n",
      "514   You are guaranteed the latest Nokia Phone, a 4...    0.997909\n",
      "3826  Congratulations U can claim 2 VIP row A Ticket...    0.997593\n",
      "4010  Please call our customer service representativ...    0.997498\n",
      "5002  CDs 4u: Congratulations ur awarded å£500 of CD...    0.997155\n",
      "1886  Dear 0776xxxxxxx U've been invited to XCHAT. T...    0.996682\n",
      "3227  SIX chances to win CASH! From 100 to 20,000 po...    0.996614\n",
      "3172  Dear Voucher Holder, To claim this weeks offer...    0.996608\n",
      "4235  U can WIN å£100 of Music Gift Vouchers every w...    0.996561\n",
      "3124  1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...    0.996482\n",
      "4434  Don't b floppy... b snappy & happy! Only gay c...    0.996316\n",
      "2668  Wanna get laid 2nite? Want real Dogging locati...    0.996066\n",
      "5137  YOU VE WON! Your 4* Costa Del Sol Holiday or å...    0.995899\n",
      "2573  Congrats 2 mobile 3G Videophones R yours. call...    0.995836\n",
      "2188  FREE camera phones with linerental from 4.49/m...    0.995779\n",
      "4448  Urgent UR awarded a complimentary trip to Euro...    0.995595\n",
      "...                                                 ...         ...\n",
      "3292  A little. Meds say take once every 8 hours. It...    0.000025\n",
      "5059                     I think i am disturbing her da    0.000025\n",
      "3981  His frens go then he in lor. Not alone wif my ...    0.000024\n",
      "1823  Same as u... Dun wan... Y u dun like me alread...    0.000023\n",
      "5166  Y she dun believe leh? I tot i told her it's t...    0.000022\n",
      "5073  I want to sent  &lt;#&gt; mesages today. Thats...    0.000022\n",
      "2681                        I'm on da bus going home...    0.000022\n",
      "4729  I dont know ask to my brother. Nothing problem...    0.000022\n",
      "1539  You're not sure that I'm not trying to make xa...    0.000021\n",
      "4432  Can u look 4 me in da lib i got stuff havent f...    0.000021\n",
      "3833         Watching tv lor. Nice one then i like lor.    0.000021\n",
      "3953  I probably won't eat at all today. I think I'm...    0.000019\n",
      "4460  Thanks again for your reply today. When is ur ...    0.000019\n",
      "139   Got c... I lazy to type... I forgot Ì_ in lect...    0.000019\n",
      "1922  I'll be in sch fr 4-6... I dun haf da book in ...    0.000018\n",
      "4310  It so happens that there r 2waxsto do wat you ...    0.000018\n",
      "64    Ok lar i double check wif da hair dresser alre...    0.000018\n",
      "2743  But my family not responding for anything. Now...    0.000017\n",
      "2488  Aiyah e rain like quite big leh. If drizzling ...    0.000016\n",
      "3918  I wish! I don't think its gonna snow that much...    0.000015\n",
      "5096  But i'm really really broke oh. No amount is t...    0.000014\n",
      "1083  Wat makes some people dearer is not just de ha...    0.000013\n",
      "291   Haf u found him? I feel so stupid da v cam was...    0.000012\n",
      "3874  Okie but i scared u say i fat... Then u dun wa...    0.000012\n",
      "2264  Ok . . now i am in bus. . If i come soon i wil...    0.000012\n",
      "1067  Meeting u is my work. . . Tel me when shall i ...    0.000010\n",
      "5243  Of course ! Don't tease me ... You know I simp...    0.000010\n",
      "243   Although i told u dat i'm into baig face watch...    0.000010\n",
      "3746  ÌÏ neva tell me how i noe... I'm not at home i...    0.000007\n",
      "3796  For The First Time In The History 'Need' 'Comf...    0.000006\n",
      "\n",
      "[836 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(X_test)\n",
    "df2['prediction'] = output\n",
    "print (df2.sort_values('prediction', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
