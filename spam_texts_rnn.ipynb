{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                      Ok lar... Joking wif u oni...      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Text\n",
    "Y = df.Label\n",
    "# Y = LabelEncoder().fit_transform(Y)\n",
    "Y = Y.values.reshape(-1,1)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow only 1000 most frequent words in the whole corpus\n",
    "max_words = 1000\n",
    "to_token = Tokenizer(num_words=max_words)\n",
    "to_token.fit_on_texts(X_train)\n",
    "\n",
    "# Pad every message to 150 words max!\n",
    "max_len = 150\n",
    "sequences = to_token.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    '''Define RNN model in keras layer-by-layer'''\n",
    "    # model = Sequential()\n",
    "    # model.add()\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4011 samples, validate on 1003 samples\n",
      "Epoch 1/10\n",
      "4011/4011 [==============================] - 11s 3ms/step - loss: 0.3296 - acc: 0.8726 - val_loss: 0.1561 - val_acc: 0.9761\n",
      "Epoch 2/10\n",
      "4011/4011 [==============================] - 9s 2ms/step - loss: 0.0882 - acc: 0.9791 - val_loss: 0.0611 - val_acc: 0.9801\n",
      "Epoch 3/10\n",
      "4011/4011 [==============================] - 9s 2ms/step - loss: 0.0488 - acc: 0.9870 - val_loss: 0.0446 - val_acc: 0.9870\n",
      "Epoch 4/10\n",
      "4011/4011 [==============================] - 9s 2ms/step - loss: 0.0360 - acc: 0.9905 - val_loss: 0.0435 - val_acc: 0.9890\n",
      "Epoch 5/10\n",
      "4011/4011 [==============================] - 9s 2ms/step - loss: 0.0284 - acc: 0.9925 - val_loss: 0.0422 - val_acc: 0.9870\n",
      "Epoch 6/10\n",
      "4011/4011 [==============================] - 9s 2ms/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0439 - val_acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x278808ef438>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 1s 917us/step\n",
      "Test set\n",
      "  Loss: 0.022\n",
      "  Accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "test_sequences = to_token.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "output = model.predict(test_sequences_matrix)\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  prediction\n",
      "938   Urgent! call 09061749602 from Landline. Your c...    0.999998\n",
      "3629  Get the official ENGLAND poly ringtone or colo...    0.999998\n",
      "2728  Urgent Please call 09066612661 from landline. ...    0.999998\n",
      "4965  URGENT! We are trying to contact U. Todays dra...    0.999998\n",
      "3215  URGENT! We are trying to contact U. Todays dra...    0.999998\n",
      "2908  URGENT! Your Mobile number has been awarded wi...    0.999998\n",
      "5342  u r subscribed 2 TEXTCOMP 250 wkly comp. 1st w...    0.999998\n",
      "4181  Urgent! Please call 0906346330. Your ABTA comp...    0.999997\n",
      "843   Urgent! call 09066350750 from your landline. Y...    0.999997\n",
      "2307  WIN a year supply of CDs 4 a store of ur choic...    0.999997\n",
      "812   Congratulations ur awarded either å£500 of CD ...    0.999997\n",
      "249   Congratulations ur awarded 500 of CD vouchers ...    0.999996\n",
      "4497  Latest Nokia Mobile or iPOD MP3 Player +å£400 ...    0.999996\n",
      "526   Today's Offer! Claim ur å£150 worth of discoun...    0.999995\n",
      "3187  This is the 2nd time we have tried 2 contact u...    0.999995\n",
      "367   Here is your discount code RP176781. To stop f...    0.999995\n",
      "5189  ree entry in 2 a weekly comp for a chance to w...    0.999994\n",
      "875   Shop till u Drop, IS IT YOU, either 10K, 5K, å...    0.999993\n",
      "258   We tried to contact you re your reply to our o...    0.999993\n",
      "3172  Dear Voucher Holder, To claim this weeks offer...    0.999992\n",
      "2611  Knock Knock Txt whose there to 80082 to enter ...    0.999991\n",
      "575   You have won ?1,000 cash or a ?2,000 prize! To...    0.999990\n",
      "2412  I don't know u and u don't know me. Send CHAT ...    0.999990\n",
      "5002  CDs 4u: Congratulations ur awarded å£500 of CD...    0.999986\n",
      "3970  Free video camera phones with Half Price line ...    0.999974\n",
      "67    Urgent UR awarded a complimentary trip to Euro...    0.999968\n",
      "5164  Congrats 2 mobile 3G Videophones R yours. call...    0.999962\n",
      "2547  Text82228>> Get more ringtones, logos and game...    0.999947\n",
      "3854  Free msg: Single? Find a partner in your area!...    0.999943\n",
      "1306  Enjoy the jamster videosound gold club with yo...    0.999939\n",
      "...                                                 ...         ...\n",
      "3871  I am joining today formally.Pls keep praying.w...    0.000018\n",
      "5382  I can make it up there, squeezed  &lt;#&gt;  b...    0.000018\n",
      "2483      Mm have some kanji dont eat anything heavy ok    0.000017\n",
      "4759  I'm home. Doc gave me pain meds says everythin...    0.000017\n",
      "1290  Eat jap done oso aft ur lect wat... ÌÏ got lec...    0.000017\n",
      "4775  Quite lor. But dun tell him wait he get compla...    0.000015\n",
      "206   As I entered my cabin my PA said, '' Happy B'd...    0.000015\n",
      "4049                 Ok ok take care. I can understand.    0.000015\n",
      "428   7 at esplanade.. Do Ì_ mind giving me a lift c...    0.000015\n",
      "2920    Yo, any way we could pick something up tonight?    0.000014\n",
      "4622  U need my presnts always bcz U cant mis love. ...    0.000013\n",
      "3337            K, if u bored up just come to my home..    0.000013\n",
      "2473                         Ok lor wat time Ì_ finish?    0.000012\n",
      "2748  Send his number and give reply tomorrow mornin...    0.000012\n",
      "4623  Jus finish blowing my hair. U finish dinner al...    0.000012\n",
      "4683  My life Means a lot to me, Not because I love ...    0.000012\n",
      "4159  i felt so...not any conveying reason.. Ese he....    0.000012\n",
      "5560                  Anything lor. Juz both of us lor.    0.000011\n",
      "3292  A little. Meds say take once every 8 hours. It...    0.000009\n",
      "4432  Can u look 4 me in da lib i got stuff havent f...    0.000009\n",
      "852   No da if you run that it activate the full ver...    0.000008\n",
      "5133  Hmm... Dunno leh, mayb a bag 4 goigng out dat ...    0.000008\n",
      "4027         Lol its ok I didn't remember til last nite    0.000007\n",
      "2514      Ok ill send you with in  &lt;DECIMAL&gt;  ok.    0.000007\n",
      "3902  Waiting in e car 4 my mum lor. U leh? Reach ho...    0.000006\n",
      "3684             Wake me up at  &lt;#&gt;  am morning:)    0.000006\n",
      "5393  All done, all handed in. Don't know if mega sh...    0.000005\n",
      "1630      I am going to film 2day da. At 6pm. Sorry da.    0.000005\n",
      "887   Y dun cut too short leh. U dun like ah? She fa...    0.000004\n",
      "4073  A lot of this sickness thing going round. Take...    0.000002\n",
      "\n",
      "[558 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(X_test)\n",
    "df2['prediction'] = output\n",
    "print (df2.sort_values('prediction', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
